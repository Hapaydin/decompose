{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeCmps-ANN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cj5erWsexM2h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52c4cb2b-92b5-485d-fb37-ca2aea02e152"
      },
      "source": [
        "import numpy \n",
        "import pandas as pd\n",
        "from pandas import read_csv\n",
        "import math\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from keras.layers import BatchNormalization, Dropout\n",
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0eJldqrxM29"
      },
      "source": [
        "AI_Method = \"/content/gdrive/My Drive/Colab Notebooks/Nal7/12188MT-1-ANN-SSA-Selected5b\"\n",
        "Var_LRs=[1e-2]# 1e-4,1e-5,1e-6,1e-7,1e-8,1e-9\n",
        "Var_Decays=[1e-2] # 1e-3,1e-4,1e-5,1e-6,1e-7,1e-8,1e-9\n",
        "Var_epochs=[100]# 300,500]\n",
        " \n",
        "Streamflow=pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/12188MT-1SSA-1.csv', delimiter=',')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKeLrvjKxM3N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c576a11-27c5-4635-9bbf-5d4b115f94a2"
      },
      "source": [
        "import numpy as np\n",
        "x= Streamflow.drop('Q',axis=1)\n",
        "Y= Streamflow['Q']\n",
        "x= x.drop('Wind',axis=1)\n",
        " \n",
        "x= x.drop('Q-1',axis=1)\n",
        "x= x.drop('Q-2',axis=1)\n",
        "x= x.drop('Q-3',axis=1)\n",
        "x= x.drop('MTI',axis=1)\n",
        "x= x.drop('Prep',axis=1)\n",
        "x= x.drop('Humid',axis=1)\n",
        "x= x.drop('Temp',axis=1)\n",
        "x= x.drop('MeanQ',axis=1)\n",
        "x= x.drop('Comp0',axis=1)\n",
        " \n",
        "x.head()\n",
        "x.info()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 237 entries, 0 to 236\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   Cemp1   237 non-null    float64\n",
            " 1   Comp2   237 non-null    float64\n",
            " 2   Comp3   237 non-null    float64\n",
            "dtypes: float64(3)\n",
            "memory usage: 5.7 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HP41l7mOxM3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea703e11-a217-4011-c85a-6c94a540c4c5"
      },
      "source": [
        "X=np.array(x)\n",
        "y=np.array(Y)\n",
        "print (X.shape[1])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYQVG2IOxM3p"
      },
      "source": [
        "train_size_y = int(len(y) * 0.70)\n",
        "train_size_X = int(len(X) * 0.70)\n",
        "y_train, y_test = y[0:train_size_y], y[train_size_y:len(y)]\n",
        "X_train, X_test = X[0:train_size_X], X[train_size_X:len(X)]\n",
        "\n",
        "input=X_train[1:]\n",
        "input_shape=X_train.shape[1:]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZmw4JnIxM33"
      },
      "source": [
        "from datetime import datetime\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "import numpy as geek"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZ96ms4xxM4F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b044524c-abc3-4e0d-acec-6f432d80d1f5"
      },
      "source": [
        "startTime = datetime.now()\n",
        "fileOfSummary = open(AI_Method+'_Summary_'+str(datetime.now()).replace(\":\", \".\")+'.csv', \"w\")\n",
        "fileOfSummary.write(\"Method,LR,DE,Epoch,RunTime,CCTr,CCTt,NSTr,NSTt,RMSETr,RMSETt,MAETr,MAETt\"+str(X.shape[1])+\"\\n\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "74"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UFy_CAexM4O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43659635-b1b6-467c-cb3f-494e7e0080fe"
      },
      "source": [
        "for e_LR in Var_LRs:\n",
        "    for e_decay in Var_Decays:\n",
        "        for e_epoch in Var_epochs:\n",
        "            \n",
        "            def create_ANN():\n",
        "                model = Sequential()\n",
        "                model.add(Dense(units=100, input_shape=X_train.shape[1:]))\n",
        "                model.add(BatchNormalization())\n",
        "                model.add(Activation(activation='relu'))\n",
        "                model.add(Dropout(0.2))\n",
        "                model.add(BatchNormalization())\n",
        "                model.add(Dropout(0.1))\n",
        "                model.add(Dense(1, activation='relu'))\n",
        "                return model\n",
        "            model = create_ANN()\n",
        "            \n",
        "            optimizer = keras.optimizers.Adam(lr=e_LR, decay=e_decay)\n",
        "            model.compile(optimizer=optimizer,loss='mean_squared_error')\n",
        "        \n",
        "            print(\" \")\n",
        "            print(\" \")\n",
        "            print(\"LRs:\",e_LR)\n",
        "            print(\"Decays:\",e_decay)\n",
        "            print(\"epochs:\",e_epoch)\n",
        "            history = model.fit(X_train, y_train, epochs=e_epoch, batch_size=256, verbose=0,  validation_data=(X_test, y_test), shuffle=True)\n",
        "            \n",
        "            hist_df = pd.DataFrame(history.history) \n",
        "            Time_elasped= datetime.now() - startTime\n",
        "            print('\\nTime elapsed: ', Time_elasped)\n",
        " \n",
        "            Train = model.predict(X_train)\n",
        "            Test = model.predict(X_test)\n",
        " \n",
        "            FileName=AI_Method+'-LR'+str(e_LR)+'-DE'+str(e_decay)+'-'+str(e_epoch)\n",
        "            np.savetxt(FileName+'_Train.csv', Train)\n",
        "            np.savetxt(FileName+'_Test.csv', Test)\n",
        "            #print('a',y_train.shape,Train.shape,len(y_train),len(Train))\n",
        "            Train = geek.asarray(Train)# np.loadtxt(FileName+'_Train.csv')\n",
        "            Test = geek.asarray(Test)#np.loadtxt(FileName+'_Test.csv')\n",
        " \n",
        "            Train = Train.reshape(Train.shape[0])\n",
        "            Test = Test.reshape(Test.shape[0])\n",
        " \n",
        "            print(\" \")\n",
        "            print(\"LRs:\",e_LR)\n",
        "            print(\"Decays:\",e_decay)\n",
        "            print(\"epochs:\",e_epoch)\n",
        "            #print('b',y_train.shape,Train.shape,len(y_train),len(Train))\n",
        "            print(\"Train ==>\")\n",
        "            CC_Train=np.corrcoef(y_train,Train)\n",
        "            print(\"CC_Train = %.3f\" %CC_Train[0,1])\n",
        " \n",
        "            NSTr=1 - sum((Train-y_train)**2)/sum((y_train-np.mean(y_train))**2)\n",
        "            print(\"NSTr = %.2f\" %NSTr)\n",
        " \n",
        "            rootMeanSquaredErrorTr = sqrt(mean_squared_error(y_train, Train))\n",
        "            print(\"RMSE = %.2f\" % rootMeanSquaredErrorTr)\n",
        "            MAETr=mean_absolute_error(y_train, Train)\n",
        "            print(\"MAE = %.2f\" %  MAETr)\n",
        " \n",
        "            print(\"Test ==>\")\n",
        "            CC_Test=np.corrcoef(y_test,Test)\n",
        "            print(\"CC_Test = %.3f\" %CC_Test[0,1])\n",
        " \n",
        "            NSTt=1 - sum((Test-y_test)**2)/sum((y_test-np.mean(y_test))**2)\n",
        "            print(\"NSTt = %.2f\" %NSTt)\n",
        " \n",
        "            rootMeanSquaredErrorTt = sqrt(mean_squared_error(y_test, Test))\n",
        "            print(\"RMSE = %.2f\" % rootMeanSquaredErrorTt)\n",
        "            MAETt=mean_absolute_error(y_test, Test)\n",
        "            print(\"MAE = %.2f\" %  MAETt)\n",
        " \n",
        "            fileOfSummary.write(AI_Method+','+str(e_LR)+','+str(e_decay)+','+str(e_epoch)+','+str(Time_elasped)+','+str(CC_Train[0,1])+','+str(CC_Test[0,1])+','+str(NSTr)+','+str(NSTt)+','+str(rootMeanSquaredErrorTr)+','+str(rootMeanSquaredErrorTt)+','+str(MAETr)+','+str(MAETt)+'\\n')\n",
        "            del model"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " \n",
            " \n",
            "LRs: 0.01\n",
            "Decays: 0.01\n",
            "epochs: 100\n",
            "\n",
            "Time elapsed:  0:00:04.852606\n",
            " \n",
            "LRs: 0.01\n",
            "Decays: 0.01\n",
            "epochs: 100\n",
            "Train ==>\n",
            "CC_Train = 0.742\n",
            "NSTr = 0.29\n",
            "RMSE = 1.99\n",
            "MAE = 1.05\n",
            "Test ==>\n",
            "CC_Test = 0.720\n",
            "NSTt = 0.22\n",
            "RMSE = 1.52\n",
            "MAE = 0.98\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uds-9YfxxM4e",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09609c59-18b7-4c47-9fe3-9ac7dd33512b"
      },
      "source": [
        "import io\n",
        "buf = io.StringIO()\n",
        "x.info(buf=buf)\n",
        "s = buf.getvalue()\n",
        "\n",
        "fileOfSummary.write(s)\n",
        "fileOfSummary.close()\n",
        "\n",
        "print(\"Finished\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}